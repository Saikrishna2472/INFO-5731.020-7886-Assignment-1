{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saikrishna2472/INFO-5731.020-7886-Assignment-1/blob/main/Paleru_Jai_Sai_Krishna_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Tuesday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (40 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from G2 or Capterra.\n",
        "\n",
        "(4) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the Densho Digital Repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jDyTKYs-yGit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f809a70-f171-4c3c-9f2e-2e6b93726d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TIGER Reigns: RIP to the Rajamouli Myth', \"A Visual and Musical Extravaganza Elevated by NTR's Performance\", 'NTR electrifying movements on screen and Anirudh awesome music and BGM', 'Energetic movie. Very good bgm.', '\"A Gripping Epic with Stellar Performances\"', 'Pirates of Paadhaghattam', 'The Devara Review: A Half-Baked Action Spectacle', \"Would've been a disaster if not for NTR\", 'Watch for other wordly experience', '1 time watch', 'Time wast, money wast, visuvals not clear, hero like katikapari roteen dram there is no high. Voltage actions', 'Superb movie and awesome story and terrific performance by ntr', 'DEVARA: Fear of the Red Sea', 'Worst movie ever!', 'Blockbuster movie', 'Fantastic Story line', 'Fights 1 to 50 , Ok Movie with some good scenes on the sea', 'Save your money and time', 'SUPER MOVIE AND BGM AWESOME', 'Avg content.. the will ride on JR NTRs popularity', 'Middling Action Drama', 'A Disappointing Watch with Poor VFX, Characters, and Story', 'Blockbuster movie, One of the best movie I have ever seen.', 'DEVARA BLOCKBUSTER', 'Rod movie']\n",
            "All reviews have been saved to 'all_reviews.csv'.\n",
            "                                               review\n",
            "0             TIGER Reigns: RIP to the Rajamouli Myth\n",
            "1   A Visual and Musical Extravaganza Elevated by ...\n",
            "2   NTR electrifying movements on screen and Aniru...\n",
            "3                     Energetic movie. Very good bgm.\n",
            "4         \"A Gripping Epic with Stellar Performances\"\n",
            "5                            Pirates of Paadhaghattam\n",
            "6    The Devara Review: A Half-Baked Action Spectacle\n",
            "7             Would've been a disaster if not for NTR\n",
            "8                   Watch for other wordly experience\n",
            "9                                        1 time watch\n",
            "10  Time wast, money wast, visuvals not clear, her...\n",
            "11  Superb movie and awesome story and terrific pe...\n",
            "12                        DEVARA: Fear of the Red Sea\n",
            "13                                  Worst movie ever!\n",
            "14                                  Blockbuster movie\n",
            "15                               Fantastic Story line\n",
            "16  Fights 1 to 50 , Ok Movie with some good scene...\n",
            "17                           Save your money and time\n",
            "18                        SUPER MOVIE AND BGM AWESOME\n",
            "19  Avg content.. the will ride on JR NTRs popularity\n",
            "20                              Middling Action Drama\n",
            "21  A Disappointing Watch with Poor VFX, Character...\n",
            "22  Blockbuster movie, One of the best movie I hav...\n",
            "23                                 DEVARA BLOCKBUSTER\n",
            "24                                          Rod movie\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the website you want to scrape\n",
        "url = 'https://www.imdb.com/title/tt11821912/reviews/?ref_=tt_urv_sm'\n",
        "\n",
        "# Custom headers\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Send a GET request to the URL with custom headers\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "all_reviews = []\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the page content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all review summaries\n",
        "    review_summary = soup.find_all('span', {'data-testid': 'review-summary'})\n",
        "\n",
        "    # Extract the text of each review and store in the list\n",
        "    for review in review_summary:\n",
        "        review_text = review.get_text(strip=True)\n",
        "        all_reviews.append(review_text)\n",
        "\n",
        "    # Print reviews (optional)\n",
        "    print(all_reviews)\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
        "\n",
        "# Save the reviews to a CSV file\n",
        "df = pd.DataFrame(all_reviews, columns=['review'])\n",
        "df.to_csv('all_reviews.csv', index=False)\n",
        "\n",
        "print(\"All reviews have been saved to 'all_reviews.csv'.\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274f7628-6940-496e-a1bd-02252da541e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned reviews have been written to 'cleaned_reviews.csv'.\n",
            "                                               review  \\\n",
            "0             TIGER Reigns: RIP to the Rajamouli Myth   \n",
            "1   A Visual and Musical Extravaganza Elevated by ...   \n",
            "2   NTR electrifying movements on screen and Aniru...   \n",
            "3                     Energetic movie. Very good bgm.   \n",
            "4         \"A Gripping Epic with Stellar Performances\"   \n",
            "5                            Pirates of Paadhaghattam   \n",
            "6    The Devara Review: A Half-Baked Action Spectacle   \n",
            "7             Would've been a disaster if not for NTR   \n",
            "8                   Watch for other wordly experience   \n",
            "9                                        1 time watch   \n",
            "10  Time wast, money wast, visuvals not clear, her...   \n",
            "11  Superb movie and awesome story and terrific pe...   \n",
            "12                        DEVARA: Fear of the Red Sea   \n",
            "13                                  Worst movie ever!   \n",
            "14                                  Blockbuster movie   \n",
            "15                               Fantastic Story line   \n",
            "16  Fights 1 to 50 , Ok Movie with some good scene...   \n",
            "17                           Save your money and time   \n",
            "18                        SUPER MOVIE AND BGM AWESOME   \n",
            "19  Avg content.. the will ride on JR NTRs popularity   \n",
            "20                              Middling Action Drama   \n",
            "21  A Disappointing Watch with Poor VFX, Character...   \n",
            "22  Blockbuster movie, One of the best movie I hav...   \n",
            "23                                 DEVARA BLOCKBUSTER   \n",
            "24                                          Rod movie   \n",
            "\n",
            "                                         clean_review  \n",
            "0                      tiger reign rip rajamouli myth  \n",
            "1          visual music extravaganza elev ntr perform  \n",
            "2   ntr electrifi movement screen anirudh awesom m...  \n",
            "3                               energet movi good bgm  \n",
            "4                           grip epic stellar perform  \n",
            "5                                 pirat paadhaghattam  \n",
            "6               devara review halfbak action spectacl  \n",
            "7                                   wouldv disast ntr  \n",
            "8                                 watch wordli experi  \n",
            "9                                          time watch  \n",
            "10  time wast money wast visuv clear hero like kat...  \n",
            "11        superb movi awesom stori terrif perform ntr  \n",
            "12                                devara fear red sea  \n",
            "13                                    worst movi ever  \n",
            "14                                     blockbust movi  \n",
            "15                                 fantast stori line  \n",
            "16                       fight ok movi good scene sea  \n",
            "17                                    save money time  \n",
            "18                              super movi bgm awesom  \n",
            "19                    avg content ride jr ntr popular  \n",
            "20                                 middl action drama  \n",
            "21            disappoint watch poor vfx charact stori  \n",
            "22             blockbust movi one best movi ever seen  \n",
            "23                                   devara blockbust  \n",
            "24                                           rod movi  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the CSV file containing the reviews\n",
        "df = pd.read_csv('all_reviews.csv')\n",
        "\n",
        "# Initialize the stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    # (1) Remove noise (special characters and punctuation)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # (2) Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # (3) Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "    # (4) Lowercase all texts\n",
        "    text = text.lower()\n",
        "\n",
        "    # (5) Stemming\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "    # (6) Lemmatization\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the review column\n",
        "df['clean_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "df.to_csv('cleaned_reviews.csv', index=False)\n",
        "\n",
        "print(\"Cleaned reviews have been written to 'cleaned_reviews.csv'.\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbd3ce2-bc27-431c-c7ef-15c39cf16593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "POS counts for review 1: Counter({'NN': 5})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "tiger --> compound --> reign\n",
            "reign --> compound --> rajamouli\n",
            "rip --> compound --> rajamouli\n",
            "rajamouli --> compound --> myth\n",
            "myth --> ROOT --> myth\n",
            "\n",
            "Entities for review 1: Counter()\n",
            "\n",
            "POS counts for review 2: Counter({'NN': 4, 'JJ': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "visual --> amod --> music\n",
            "music --> compound --> extravaganza\n",
            "extravaganza --> compound --> elev\n",
            "elev --> nsubj --> ntr\n",
            "ntr --> aux --> perform\n",
            "perform --> ROOT --> perform\n",
            "\n",
            "Entities for review 2: Counter()\n",
            "\n",
            "POS counts for review 3: Counter({'NN': 6, 'JJ': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "ntr --> compound --> bgm\n",
            "electrifi --> compound --> movement\n",
            "movement --> compound --> screen\n",
            "screen --> compound --> anirudh\n",
            "anirudh --> compound --> bgm\n",
            "awesom --> compound --> music\n",
            "music --> compound --> bgm\n",
            "bgm --> ROOT --> bgm\n",
            "\n",
            "Entities for review 3: Counter({('ntr electrifi', 'ORG'): 1})\n",
            "\n",
            "POS counts for review 4: Counter({'NN': 2, 'VB': 1, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "energet --> ROOT --> energet\n",
            "movi --> compound --> bgm\n",
            "good --> compound --> bgm\n",
            "bgm --> dobj --> energet\n",
            "\n",
            "Entities for review 4: Counter()\n",
            "\n",
            "POS counts for review 5: Counter({'NN': 3, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "grip --> nmod --> perform\n",
            "epic --> amod --> perform\n",
            "stellar --> amod --> perform\n",
            "perform --> ROOT --> perform\n",
            "\n",
            "Entities for review 5: Counter()\n",
            "\n",
            "POS counts for review 6: Counter({'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "pirat --> compound --> paadhaghattam\n",
            "paadhaghattam --> ROOT --> paadhaghattam\n",
            "\n",
            "Entities for review 6: Counter()\n",
            "\n",
            "POS counts for review 7: Counter({'NN': 4, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "devara --> compound --> review\n",
            "review --> compound --> spectacl\n",
            "halfbak --> amod --> spectacl\n",
            "action --> compound --> spectacl\n",
            "spectacl --> ROOT --> spectacl\n",
            "\n",
            "Entities for review 7: Counter({('devara', 'PERSON'): 1, ('halfbak', 'ORG'): 1, ('spectacl', 'ORG'): 1})\n",
            "\n",
            "POS counts for review 8: Counter({'NN': 3})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "wouldv --> compound --> disast\n",
            "disast --> nsubj --> ntr\n",
            "ntr --> ROOT --> ntr\n",
            "\n",
            "Entities for review 8: Counter()\n",
            "\n",
            "POS counts for review 9: Counter({'NN': 3})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "watch --> ROOT --> watch\n",
            "wordli --> nsubj --> experi\n",
            "experi --> ccomp --> watch\n",
            "\n",
            "Entities for review 9: Counter({('wordli experi', 'PERSON'): 1})\n",
            "\n",
            "POS counts for review 10: Counter({'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "time --> npadvmod --> watch\n",
            "watch --> ROOT --> watch\n",
            "\n",
            "Entities for review 10: Counter()\n",
            "\n",
            "POS counts for review 11: Counter({'NN': 9, 'JJ': 3, 'IN': 1, 'RB': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "time --> npadvmod --> wast\n",
            "wast --> compound --> money\n",
            "money --> appos --> time\n",
            "wast --> compound --> visuv\n",
            "visuv --> nsubj --> hero\n",
            "clear --> amod --> hero\n",
            "hero --> ROOT --> hero\n",
            "like --> prep --> hero\n",
            "katikapari --> pobj --> like\n",
            "roteen --> compound --> dram\n",
            "dram --> nmod --> action\n",
            "high --> amod --> action\n",
            "voltag --> compound --> action\n",
            "action --> appos --> hero\n",
            "\n",
            "Entities for review 11: Counter({('katikapari roteen dram high', 'ORG'): 1})\n",
            "\n",
            "POS counts for review 12: Counter({'NN': 6, 'FW': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "superb --> compound --> movi\n",
            "movi --> compound --> stori\n",
            "awesom --> compound --> stori\n",
            "stori --> compound --> terrif\n",
            "terrif --> nsubj --> perform\n",
            "perform --> ROOT --> perform\n",
            "ntr --> dobj --> perform\n",
            "\n",
            "Entities for review 12: Counter({('superb movi awesom', 'ORG'): 1, ('terrif perform', 'PERSON'): 1})\n",
            "\n",
            "POS counts for review 13: Counter({'NN': 3, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "devara --> compound --> sea\n",
            "fear --> compound --> sea\n",
            "red --> compound --> sea\n",
            "sea --> ROOT --> sea\n",
            "\n",
            "Entities for review 13: Counter({('devara', 'PERSON'): 1})\n",
            "\n",
            "POS counts for review 14: Counter({'JJS': 1, 'NN': 1, 'RB': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "worst --> amod --> movi\n",
            "movi --> ROOT --> movi\n",
            "ever --> advmod --> movi\n",
            "\n",
            "Entities for review 14: Counter()\n",
            "\n",
            "POS counts for review 15: Counter({'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "blockbust --> advmod --> movi\n",
            "movi --> ROOT --> movi\n",
            "\n",
            "Entities for review 15: Counter()\n",
            "\n",
            "POS counts for review 16: Counter({'NN': 2, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "fantast --> compound --> stori\n",
            "stori --> compound --> line\n",
            "line --> ROOT --> line\n",
            "\n",
            "Entities for review 16: Counter()\n",
            "\n",
            "POS counts for review 17: Counter({'RB': 2, 'JJ': 2, 'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "fight --> ROOT --> fight\n",
            "ok --> prep --> fight\n",
            "movi --> nmod --> sea\n",
            "good --> amod --> scene\n",
            "scene --> compound --> sea\n",
            "sea --> dobj --> fight\n",
            "\n",
            "Entities for review 17: Counter()\n",
            "\n",
            "POS counts for review 18: Counter({'NN': 2, 'VB': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "save --> ROOT --> save\n",
            "money --> compound --> time\n",
            "time --> dobj --> save\n",
            "\n",
            "Entities for review 18: Counter()\n",
            "\n",
            "POS counts for review 19: Counter({'NN': 3, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "super --> amod --> movi\n",
            "movi --> nsubj --> bgm\n",
            "bgm --> ROOT --> bgm\n",
            "awesom --> dobj --> bgm\n",
            "\n",
            "Entities for review 19: Counter({('super movi', 'ORG'): 1})\n",
            "\n",
            "POS counts for review 20: Counter({'NN': 4, 'IN': 1, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "avg --> compound --> content\n",
            "content --> compound --> ride\n",
            "ride --> nsubj --> ntr\n",
            "jr --> advmod --> ride\n",
            "ntr --> ROOT --> ntr\n",
            "popular --> acomp --> ntr\n",
            "\n",
            "Entities for review 20: Counter()\n",
            "\n",
            "POS counts for review 21: Counter({'NN': 2, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "middl --> amod --> action\n",
            "action --> compound --> drama\n",
            "drama --> ROOT --> drama\n",
            "\n",
            "Entities for review 21: Counter()\n",
            "\n",
            "POS counts for review 22: Counter({'NN': 5, 'JJ': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "disappoint --> nsubj --> watch\n",
            "watch --> ROOT --> watch\n",
            "poor --> amod --> stori\n",
            "vfx --> compound --> charact\n",
            "charact --> compound --> stori\n",
            "stori --> dobj --> watch\n",
            "\n",
            "Entities for review 22: Counter()\n",
            "\n",
            "POS counts for review 23: Counter({'NN': 2, 'VB': 1, 'CD': 1, 'JJS': 1, 'RB': 1, 'VBN': 1})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "blockbust --> advmod --> movi\n",
            "movi --> dep --> seen\n",
            "one --> nummod --> movi\n",
            "best --> amod --> movi\n",
            "movi --> nsubj --> seen\n",
            "ever --> advmod --> seen\n",
            "seen --> ROOT --> seen\n",
            "\n",
            "Entities for review 23: Counter()\n",
            "\n",
            "POS counts for review 24: Counter({'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "devara --> ROOT --> devara\n",
            "blockbust --> advmod --> devara\n",
            "\n",
            "Entities for review 24: Counter({('devara', 'PERSON'): 1})\n",
            "\n",
            "POS counts for review 25: Counter({'NN': 2})\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "rod --> compound --> movi\n",
            "movi --> ROOT --> movi\n",
            "\n",
            "Entities for review 25: Counter({('rod movi', 'PERSON'): 1})\n",
            "\n",
            "Overall entity counts: Counter({('devara', 'PERSON'): 3, ('ntr electrifi', 'ORG'): 1, ('halfbak', 'ORG'): 1, ('spectacl', 'ORG'): 1, ('wordli experi', 'PERSON'): 1, ('katikapari roteen dram high', 'ORG'): 1, ('superb movi awesom', 'ORG'): 1, ('terrif perform', 'PERSON'): 1, ('super movi', 'ORG'): 1, ('rod movi', 'PERSON'): 1})\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the cleaned reviews\n",
        "df = pd.read_csv('cleaned_reviews.csv')\n",
        "\n",
        "# Initialize spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Parts of Speech Tagging and Counting\n",
        "def pos_analysis(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "    pos_counts = Counter(tag for word, tag in tagged)\n",
        "    return pos_counts\n",
        "\n",
        "# Dependency Parsing\n",
        "def parse_sentence(text):\n",
        "    doc = nlp(text)\n",
        "    print(\"\\nDependency Parsing Tree:\")\n",
        "    for sent in doc.sents:\n",
        "        for token in sent:\n",
        "            print(f\"{token.text} --> {token.dep_} --> {token.head.text}\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "def named_entity_recognition(text):\n",
        "    doc = nlp(text)\n",
        "    entities = Counter((ent.text, ent.label_) for ent in doc.ents)\n",
        "    return entities\n",
        "\n",
        "# Analyze each review\n",
        "for index, row in df.iterrows():\n",
        "    text = row['clean_review']\n",
        "\n",
        "    # POS Analysis\n",
        "    pos_counts = pos_analysis(text)\n",
        "    print(f\"\\nPOS counts for review {index + 1}: {pos_counts}\")\n",
        "\n",
        "    # Parse Sentence\n",
        "    parse_sentence(text)\n",
        "\n",
        "    # Named Entity Recognition\n",
        "    entities = named_entity_recognition(text)\n",
        "    print(f\"\\nEntities for review {index + 1}: {entities}\")\n",
        "\n",
        "# Summarize entity counts\n",
        "all_entities = Counter()\n",
        "for index, row in df.iterrows():\n",
        "    text = row['clean_review']\n",
        "    entities = named_entity_recognition(text)\n",
        "    all_entities.update(entities)\n",
        "\n",
        "print(\"\\nOverall entity counts:\", all_entities)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXNn1lEVbMsv"
      },
      "source": [
        "#**Comment**\n",
        "Make sure to submit the cleaned data CSV in the comment section - 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qYRO5Cn8bYwZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7711e586-91dc-40a9-ea03-4b6b5a2ec4b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dba43cf6-ba34-47c9-81f7-a3c5d7c2cc30\", \"cleaned_reviews.csv\", 1739)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the cleaned_reviews.csv file\n",
        "files.download('cleaned_reviews.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8BFCvWp32cf"
      },
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e557s2w4BpK"
      },
      "outputs": [],
      "source": [
        "# Write your response below\n",
        "# Challenges:\n",
        "# Data Scraping: Setting up web scraping can be tricky due to varying HTML structures and potential anti-scraping measures. Debugging issues can be time-consuming.\n",
        "# Data Cleaning: The multiple steps in cleaning text data require attention to detail, and managing different libraries like NLTK and spaCy can lead to confusion.\n",
        "# Syntax Analysis: Understanding POS tagging and parsing can be complex, needing a solid grasp of linguistic concepts.\n",
        "\n",
        "# Enjoyable Aspects:\n",
        "# Learning Opportunities: Each step offers a chance to learn new techniques and tools, particularly in NLP.\n",
        "# Problem Solving: Overcoming errors and achieving accurate results can be fulfilling and enhance critical thinking.\n",
        "# Visualization: Seeing cleaned data and analysis results is satisfying and demonstrates effective processing.\n",
        "\n",
        "# Opinion on Time Allocation:\n",
        "# Time Considerations: The time needed varies; experienced individuals may find it adequate, while beginners might feel rushed.\n",
        "# Iterative Nature: Additional time for experimentation and debugging could enhance learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}